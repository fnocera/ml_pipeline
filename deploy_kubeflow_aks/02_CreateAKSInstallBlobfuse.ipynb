{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Kubernetes Services (AKS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will first provision an AKS cluster and install blobfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from environs import Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define the names and configurations of the resources that will be provisioned on Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = Env()\n",
    "ENV.read_env()\n",
    "\n",
    "subscription_id = ENV(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = ENV(\"AZURE_RESOURCE_GROUP\") #  i.e.'kuberg'\n",
    "location = ENV(\"AZURE_RESOURCE_LOCATION\") # i.e. 'eastus'\n",
    "agent_size = \"Standard_NC6\" # i.e. 'Standard_NC6', Standard_D1_v2\n",
    "aks_name = ENV(\"AKS_NAME\") # i.e. 'kubeaks'\n",
    "agent_count = 1 # agent count is the number of VMs that will be provisioned in the cluster, you can pick any number.\n",
    "storage_account = \"fenocerakubestorage\"#ENV(\"STORAGE_ACCOUNT_NAME\") # i.e. 'kubest'\n",
    "storage_container = ENV(\"AKS_CONTAINER\") # i.e. 'blobfuse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and initialize a dotenv file for storing parameters used in multiple notebooks.\n",
    "\n",
    "DONT THINK THIS SHOULD BE HERE!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_path = find_dotenv()\n",
    "# if env_path == \"\":\n",
    "#     Path(\".env\").touch()\n",
    "#     env_path = find_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_key(env_path, 'subscription_id', subscription_id) \n",
    "# set_key(env_path, 'resource_group', resource_group)\n",
    "# set_key(env_path, 'storage_account', storage_account)\n",
    "# set_key(env_path, 'storage_container', storage_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create resource group and AKS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set -s {subscription_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess you dont need this if you have a res g already\n",
    "# !az group create --name {resource_group} --location {location} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az aks create --node-vm-size {agent_size} --resource-group {resource_group} --name {aks_name} --node-count {agent_count} --kubernetes-version 1.11.6  --generate-ssh-keys --query 'provisioningState'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KubernetesVersion    Upgrades\r\n",
      "-------------------  ------------------------\r\n",
      "1.13.5               None available\r\n",
      "1.12.8               1.13.5\r\n",
      "1.12.7               1.12.8, 1.13.5\r\n",
      "1.11.9               1.12.7, 1.12.8\r\n",
      "1.11.8               1.11.9, 1.12.7, 1.12.8\r\n",
      "1.10.13              1.11.8, 1.11.9\r\n",
      "1.10.12              1.10.13, 1.11.8, 1.11.9\r\n",
      "1.9.11               1.10.12, 1.10.13\r\n",
      "1.9.10               1.9.11, 1.10.12, 1.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!az aks get-versions --location eastus --output table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need to make sure you check the version of kubernetes with `!az aks get-versions --location eastus --output table` \n",
    "- This parameter does not exist in the docs so not sure it should be there--query 'provisioningState', looks to be something relatex to az not aks create....look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"aadProfile\": null,\n",
      "  \"addonProfiles\": null,\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"availabilityZones\": null,\n",
      "      \"count\": 1,\n",
      "      \"enableAutoScaling\": null,\n",
      "      \"maxCount\": null,\n",
      "      \"maxPods\": 110,\n",
      "      \"minCount\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"orchestratorVersion\": \"1.12.8\",\n",
      "      \"osDiskSizeGb\": 100,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"provisioningState\": \"Succeeded\",\n",
      "      \"type\": \"AvailabilitySet\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"apiServerAuthorizedIpRanges\": null,\n",
      "  \"dnsPrefix\": \"kubeflowte-fenocerarg-fb45cb\",\n",
      "  \"enablePodSecurityPolicy\": null,\n",
      "  \"enableRbac\": true,\n",
      "  \"fqdn\": \"kubeflowte-fenocerarg-fb45cb-e391bb27.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/fb45cb39-23ee-447d-a047-4c8ba0a5d527/resourcegroups/fenocera_rg/providers/Microsoft.ContainerService/managedClusters/kubeflowtest\",\n",
      "  \"kubernetesVersion\": \"1.12.8\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCk7M98oOwEjH25QHIk7M+GsUZagKua/SkVENsov5iSxBvG4MpYiUEjB+066z/rZ3rF3cyzKps0elIrFQN2JSLHjjVBjPz9VGK5WB2LsaPC9kUFvbcgTIiMqe9P1DYGy+oAMQ/PeuL23NGSVAqHuyOHqQLx81k2C57GsLRiODTLl1julT51yXGT2TOfCta2QNUYuy/lTuBvTpqsuZu6tLFT0F2Y8SOjRJX10LeB0M7Cj+9W2ydUpFkYp6Pt1Q+6CNZlKdE7kdW29bae5VXLWbQ/HhC5cp2WptCzxj60h77AcQoWoJktLNqcCjuYUjwtlopSq+K+k0g6TzurziYWsyrl federica@B88L02-19.redmond.corp.microsoft.com\\n\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"kubeflowtest\",\n",
      "  \"networkProfile\": {\n",
      "    \"dnsServiceIp\": \"10.0.0.10\",\n",
      "    \"dockerBridgeCidr\": \"172.17.0.1/16\",\n",
      "    \"networkPlugin\": \"kubenet\",\n",
      "    \"networkPolicy\": null,\n",
      "    \"podCidr\": \"10.244.0.0/16\",\n",
      "    \"serviceCidr\": \"10.0.0.0/16\"\n",
      "  },\n",
      "  \"nodeResourceGroup\": \"MC_fenocera_rg_kubeflowtest_eastus\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"fenocera_rg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"0a9b6ef8-86fd-4a6a-8f83-9380c7356d64\",\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks create --resource-group {resource_group} --node-vm-size {agent_size} --name {aks_name} --node-count {agent_count} --generate-ssh-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install kubectl to connect to the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's connect to AKS cluster and get the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A different object named kubeflowtest already exists in your kubeconfig file.\n",
      "Overwrite? (y/n): ^C\n"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group {resource_group} --name {aks_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-34660992-0   Ready     agent     4m        v1.12.8\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:               aks-nodepool1-34660992-0\r\n",
      "Roles:              agent\r\n",
      "Labels:             accelerator=nvidia\r\n",
      "                    agentpool=nodepool1\r\n",
      "                    beta.kubernetes.io/arch=amd64\r\n",
      "                    beta.kubernetes.io/instance-type=Standard_NC6\r\n",
      "                    beta.kubernetes.io/os=linux\r\n",
      "                    failure-domain.beta.kubernetes.io/region=eastus\r\n",
      "                    failure-domain.beta.kubernetes.io/zone=0\r\n",
      "                    kubernetes.azure.com/cluster=MC_fenocera_rg_kubeflowtest_eastus\r\n",
      "                    kubernetes.io/hostname=aks-nodepool1-34660992-0\r\n",
      "                    kubernetes.io/role=agent\r\n",
      "                    node-role.kubernetes.io/agent=\r\n",
      "                    storageprofile=managed\r\n",
      "                    storagetier=Standard_LRS\r\n",
      "Annotations:        node.alpha.kubernetes.io/ttl=0\r\n",
      "                    volumes.kubernetes.io/controller-managed-attach-detach=true\r\n",
      "CreationTimestamp:  Tue, 21 May 2019 21:27:38 -0400\r\n",
      "Taints:             <none>\r\n",
      "Unschedulable:      false\r\n",
      "Conditions:\r\n",
      "  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\r\n",
      "  ----                 ------  -----------------                 ------------------                ------                       -------\r\n",
      "  NetworkUnavailable   False   Tue, 21 May 2019 21:29:02 -0400   Tue, 21 May 2019 21:29:02 -0400   RouteCreated                 RouteController created a route\r\n",
      "  OutOfDisk            False   Tue, 21 May 2019 21:32:30 -0400   Tue, 21 May 2019 21:27:38 -0400   KubeletHasSufficientDisk     kubelet has sufficient disk space available\r\n",
      "  MemoryPressure       False   Tue, 21 May 2019 21:32:30 -0400   Tue, 21 May 2019 21:27:38 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available\r\n",
      "  DiskPressure         False   Tue, 21 May 2019 21:32:30 -0400   Tue, 21 May 2019 21:27:38 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure\r\n",
      "  PIDPressure          False   Tue, 21 May 2019 21:32:30 -0400   Tue, 21 May 2019 21:27:38 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available\r\n",
      "  Ready                True    Tue, 21 May 2019 21:32:30 -0400   Tue, 21 May 2019 21:27:41 -0400   KubeletReady                 kubelet is posting ready status. AppArmor enabled\r\n",
      "Addresses:\r\n",
      "  Hostname:    aks-nodepool1-34660992-0\r\n",
      "  InternalIP:  10.240.0.4\r\n",
      "Capacity:\r\n",
      " attachable-volumes-azure-disk:  24\r\n",
      " cpu:                            6\r\n",
      " ephemeral-storage:              101584140Ki\r\n",
      " hugepages-1Gi:                  0\r\n",
      " hugepages-2Mi:                  0\r\n",
      " memory:                         57690556Ki\r\n",
      " pods:                           110\r\n",
      "Allocatable:\r\n",
      " attachable-volumes-azure-disk:  24\r\n",
      " cpu:                            5916m\r\n",
      " ephemeral-storage:              93619943269\r\n",
      " hugepages-1Gi:                  0\r\n",
      " hugepages-2Mi:                  0\r\n",
      " memory:                         51679676Ki\r\n",
      " pods:                           110\r\n",
      "System Info:\r\n",
      " Machine ID:                 cdb01f2d1dc24302a918069b228571fc\r\n",
      " System UUID:                AB785EE8-FCB8-2B4B-B7FF-026D6E8133B5\r\n",
      " Boot ID:                    25056e6b-47aa-4209-b8df-1f1c11e22008\r\n",
      " Kernel Version:             4.15.0-1042-azure\r\n",
      " OS Image:                   Ubuntu 16.04.6 LTS\r\n",
      " Operating System:           linux\r\n",
      " Architecture:               amd64\r\n",
      " Container Runtime Version:  docker://3.0.4\r\n",
      " Kubelet Version:            v1.12.8\r\n",
      " Kube-Proxy Version:         v1.12.8\r\n",
      "PodCIDR:                     10.244.0.0/24\r\n",
      "ExternalID:                  aks-nodepool1-34660992-0\r\n",
      "ProviderID:                  azure:///subscriptions/fb45cb39-23ee-447d-a047-4c8ba0a5d527/resourceGroups/MC_fenocera_rg_kubeflowtest_eastus/providers/Microsoft.Compute/virtualMachines/aks-nodepool1-34660992-0\r\n",
      "Non-terminated Pods:         (9 in total)\r\n",
      "  Namespace                  Name                                     CPU Requests  CPU Limits  Memory Requests  Memory Limits\r\n",
      "  ---------                  ----                                     ------------  ----------  ---------------  -------------\r\n",
      "  kube-system                coredns-66cb57b9db-4thcv                 100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)\r\n",
      "  kube-system                coredns-66cb57b9db-zbmrl                 100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)\r\n",
      "  kube-system                coredns-autoscaler-7fd449d848-rjszm      20m (0%)      0 (0%)      10Mi (0%)        0 (0%)\r\n",
      "  kube-system                heapster-7677c744b8-jqrnp                130m (2%)     130m (2%)   230Mi (0%)       230Mi (0%)\r\n",
      "  kube-system                kube-proxy-864x4                         100m (1%)     0 (0%)      0 (0%)           0 (0%)\r\n",
      "  kube-system                kube-svc-redirect-n6tqz                  10m (0%)      0 (0%)      34Mi (0%)        0 (0%)\r\n",
      "  kube-system                kubernetes-dashboard-7b55c6f7b9-xpg8k    100m (1%)     100m (1%)   50Mi (0%)        500Mi (0%)\r\n",
      "  kube-system                metrics-server-67c75dbf7-8g9zk           0 (0%)        0 (0%)      0 (0%)           0 (0%)\r\n",
      "  kube-system                tunnelfront-7bc54c5887-k28v9             10m (0%)      0 (0%)      64Mi (0%)        0 (0%)\r\n",
      "Allocated resources:\r\n",
      "  (Total limits may be over 100 percent, i.e., overcommitted.)\r\n",
      "  CPU Requests  CPU Limits  Memory Requests  Memory Limits\r\n",
      "  ------------  ----------  ---------------  -------------\r\n",
      "  570m (9%)     230m (3%)   528Mi (1%)       1070Mi (2%)\r\n",
      "Events:\r\n",
      "  Type    Reason                   Age   From                                  Message\r\n",
      "  ----    ------                   ----  ----                                  -------\r\n",
      "  Normal  Starting                 4m    kubelet, aks-nodepool1-34660992-0     Starting kubelet.\r\n",
      "  Normal  NodeHasSufficientDisk    4m    kubelet, aks-nodepool1-34660992-0     Node aks-nodepool1-34660992-0 status is now: NodeHasSufficientDisk\r\n",
      "  Normal  NodeHasSufficientMemory  4m    kubelet, aks-nodepool1-34660992-0     Node aks-nodepool1-34660992-0 status is now: NodeHasSufficientMemory\r\n",
      "  Normal  NodeHasNoDiskPressure    4m    kubelet, aks-nodepool1-34660992-0     Node aks-nodepool1-34660992-0 status is now: NodeHasNoDiskPressure\r\n",
      "  Normal  NodeHasSufficientPID     4m    kubelet, aks-nodepool1-34660992-0     Node aks-nodepool1-34660992-0 status is now: NodeHasSufficientPID\r\n",
      "  Normal  NodeAllocatableEnforced  4m    kubelet, aks-nodepool1-34660992-0     Updated Node Allocatable limit across pods\r\n",
      "  Normal  NodeReady                4m    kubelet, aks-nodepool1-34660992-0     Node aks-nodepool1-34660992-0 status is now: NodeReady\r\n",
      "  Normal  Starting                 4m    kube-proxy, aks-nodepool1-34660992-0  Starting kube-proxy.\r\n"
     ]
    }
   ],
   "source": [
    "node_names = !kubectl get nodes -o name\n",
    "!kubectl describe node {node_names[0].strip('node/')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the following deamonset to enable GPU support in Kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daemonset.extensions \"nvidia-device-plugin-daemonset\" created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS              RESTARTS   AGE\r\n",
      "kube-system   coredns-66cb57b9db-4thcv                1/1       Running             0          4m\r\n",
      "kube-system   coredns-66cb57b9db-zbmrl                1/1       Running             0          9m\r\n",
      "kube-system   coredns-autoscaler-7fd449d848-rjszm     1/1       Running             0          9m\r\n",
      "kube-system   heapster-7677c744b8-jqrnp               2/2       Running             0          9m\r\n",
      "kube-system   kube-proxy-864x4                        1/1       Running             0          5m\r\n",
      "kube-system   kube-svc-redirect-n6tqz                 2/2       Running             0          5m\r\n",
      "kube-system   kubernetes-dashboard-7b55c6f7b9-xpg8k   1/1       Running             0          9m\r\n",
      "kube-system   metrics-server-67c75dbf7-8g9zk          1/1       Running             0          9m\r\n",
      "kube-system   nvidia-device-plugin-daemonset-njsm6    0/1       ContainerCreating   0          1s\r\n",
      "kube-system   tunnelfront-7bc54c5887-k28v9            1/1       Running             0          9m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach blobfuse on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [blobfuse](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux) using [blobfuse volume driver for Kubernetes](https://github.com/Azure/kubernetes-volume-drivers/tree/master/flexvolume/blobfuse) to store the model servables for Kubeflow tensorflow serving component to serve the model from. The driver requires that a storage account and a container created in the same region with the kubernetes cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storage account and copy model servable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create that storage account. or we can use an existing storage account?! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K - Starting ..\r",
      "\r",
      "\u001b[K - Finished ..\r",
      "\r",
      "\u001b[K\"Succeeded\"\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az storage account create -n {storage_account} -g {resource_group} --query 'provisioningState'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the first storage acount key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = !az storage account keys list --account-name {storage_account} -g {resource_group} --query '[0].value'\n",
    "storage_account_key = str(key[0][1:-1]) # clean up key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_container = \"kubetestcont\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the container to be used by blobfuse driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\r\n",
      "Missing credentials to access storage service. The following variations are accepted:\r\n",
      "    (1) account name and key (--account-name and --account-key options or\r\n",
      "        set AZURE_STORAGE_ACCOUNT and AZURE_STORAGE_KEY environment variables)\r\n",
      "    (2) account name and SAS token (--sas-token option used with either the --account-name\r\n",
      "        option or AZURE_STORAGE_ACCOUNT environment variable)\r\n",
      "    (3) account name (--account-name option or AZURE_STORAGE_ACCOUNT environment variable;\r\n",
      "        this will make calls to query for a storage account key using login credentials)\r\n",
      "    (4) connection string (--connection-string option or\r\n",
      "        set AZURE_STORAGE_CONNECTION_STRING environment variable); some shells will require\r\n",
      "        quoting to preserve literal character interpretation.\r\n",
      "\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!az storage container create --name {storage_container} --account-key {storage_account_key} --account-name {storage_account}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can upload the model servables to the container. This step requires that you have azcopy installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = 'https://{}.blob.core.windows.net/{}'.format(storage_account, storage_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING MAC SO UPLOADED models folder directly to blob manually \n",
    "\n",
    "#!azcopy --source models --destination {destination} --dest-key {storage_account_key} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install blobfuse driver on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy the following deamonset to enable blobfuse on every node of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT GOING TO RUN THE BLOBFUSE INSTALLER AS A TEST!!\n",
    "\n",
    "#! kubectl create -f https://raw.githubusercontent.com/Azure/kubernetes-volume-drivers/master/flexvolume/blobfuse/deployment/blobfuse-flexvol-installer-1.9.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "kube-system   coredns-66cb57b9db-4thcv                1/1       Running   0          5m\r\n",
      "kube-system   coredns-66cb57b9db-zbmrl                1/1       Running   0          10m\r\n",
      "kube-system   coredns-autoscaler-7fd449d848-rjszm     1/1       Running   0          10m\r\n",
      "kube-system   heapster-7677c744b8-jqrnp               2/2       Running   0          10m\r\n",
      "kube-system   kube-proxy-864x4                        1/1       Running   0          5m\r\n",
      "kube-system   kube-svc-redirect-n6tqz                 2/2       Running   0          5m\r\n",
      "kube-system   kubernetes-dashboard-7b55c6f7b9-xpg8k   1/1       Running   0          10m\r\n",
      "kube-system   metrics-server-67c75dbf7-8g9zk          1/1       Running   0          10m\r\n",
      "kube-system   nvidia-device-plugin-daemonset-njsm6    1/1       Running   0          50s\r\n",
      "kube-system   tunnelfront-7bc54c5887-k28v9            1/1       Running   0          10m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl describe daemonset blobfuse-flexvol-installer --namespace=kube-system # BUG HERE AS NAMESPACE WAS WRONG!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can move on to [installing Kubeflow and serving the model on AKS with kubeflow tensorflow serving component](03_ServeWithKubeflow.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
